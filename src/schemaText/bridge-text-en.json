{
  "emqx_connector_schema_lib": {
    "auto_reconnect": {
      "desc": "Deprecated. Enable automatic reconnect to the database.",
      "label": "Deprecated. Auto Reconnect Database"
    },
    "password": {
      "desc": "EMQX's password in the external database.",
      "label": "Password"
    },
    "pool_size": {
      "desc": "Size of the connection pool towards the bridge target service.",
      "label": "Connection Pool Size"
    },
    "prepare_statement": {
      "desc": "Key-value list of SQL prepared statements.",
      "label": "SQL Prepared Statements List"
    },
    "ssl": {
      "desc": "SSL connection settings.",
      "label": "Enable SSL"
    },
    "username": {
      "desc": "EMQX's username in the external database.",
      "label": "Username"
    },
    "database": {
      "desc": "Database name.",
      "label": "Database Name"
    }
  },
  "emqx_ee_bridge_cassa": {
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a Cassandra bridge.",
      "label": "Cassandra Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Cassandra. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "keyspace": {
      "desc": "Keyspace name to connect to.",
      "label": "Keyspace"
    },
    "servers": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port][,Host2:Port]`.<br/>\nThe Cassandra default port 9042 is used if `[:Port]` is not specified.",
      "label": "Servers"
    },
    "cql": {
      "desc": "CQL Template",
      "label": "CQL Template"
    }
  },
  "emqx_ee_bridge_clickhouse": {
    "batch_value_separator": {
      "desc": "The default value ',' works for the VALUES format. You can also use other separator if other format is specified. See [INSERT INTO Statement](https://clickhouse.com/docs/en/sql-reference/statements/insert-into).",
      "label": "Batch Value Separator"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a Clickhouse bridge.",
      "label": "Clickhouse Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Clickhouse. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "connect_timeout": {
      "desc": "The timeout when connecting to the Clickhouse server.",
      "label": "Clickhouse Timeout"
    },
    "url": {
      "desc": "The HTTP URL to the Clickhouse server that you want to connect to (for example http://myhostname:8123)",
      "label": "Server URL"
    },
    "sql": {
      "desc": "The template string can contain ${'{'}field{'}'} placeholders for message metadata and payload field. Make sure that the inserted values are formatted and escaped correctly. [Prepared Statement](https://docs.emqx.com/en/enterprise/v5.0/data-integration/data-bridges.html#Prepared-Statement) is not supported.",
      "label": "SQL Template"
    }
  },
  "emqx_ee_bridge_dynamo": {
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for an DynamoDB bridge.",
      "label": "DynamoDB Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to DynamoDB. All MQTT `PUBLISH` messages with the topic\nmatching the `local_topic` will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also `local_topic` is\nconfigured, then both the data got from the rule and the MQTT messages that match `local_topic`\nwill be forwarded.",
      "label": "Local Topic"
    },
    "template": {
      "desc": "Template, the default value is empty. When this value is empty the whole message will be stored in the database",
      "label": "Template"
    },
    "url": {
      "desc": "The url of DynamoDB endpoint.",
      "label": "DynamoDB Endpoint"
    }
  },
  "emqx_ee_bridge_gcp_pubsub": {
    "connect_timeout": {
      "desc": "The timeout when connecting to the HTTP server.",
      "label": "Connect Timeout"
    },
    "desc_config": {
      "desc": "Configuration for a GCP PubSub bridge.",
      "label": "GCP PubSub Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name, used as a human-readable description of the bridge.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to GCP PubSub. All MQTT 'PUBLISH' messages with the topic\nmatching `local_topic` will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "max_retries": {
      "desc": "Max retry times if an error occurs when sending a request.",
      "label": "Max Retries"
    },
    "payload_template": {
      "desc": "The template for formatting the outgoing messages.  If undefined, will send all the available context in JSON format.",
      "label": "Payload template"
    },
    "pipelining": {
      "desc": "A positive integer. Whether to send HTTP requests continuously, when set to 1, it means that after each HTTP request is sent, you need to wait for the server to return and then continue to send the next request.",
      "label": "HTTP Pipelineing"
    },
    "pool_size": {
      "desc": "The pool size.",
      "label": "Pool Size"
    },
    "pubsub_topic": {
      "desc": "The GCP PubSub topic to publish messages to.",
      "label": "GCP PubSub Topic"
    },
    "request_timeout": {
      "desc": "Deprecated: Configure the request timeout in the buffer settings.",
      "label": "Request Timeout"
    },
    "service_account_json": {
      "desc": "JSON containing the GCP Service Account credentials to be used with PubSub.\nWhen a GCP Service Account is created (as described in https://developers.google.com/identity/protocols/oauth2/service-account#creatinganaccount), you have the option of downloading the credentials in JSON form.  That's the file needed.",
      "label": "GCP Service Account Credentials"
    }
  },
  "emqx_ee_bridge_hstreamdb": {
    "config_direction": {
      "desc": "The direction of this bridge, MUST be 'egress'",
      "label": "Bridge Direction"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for an HStreamDB bridge.",
      "label": "HStreamDB Bridge Configuration"
    },
    "desc_connector": {
      "desc": "Generic configuration for the connector.",
      "label": "Connector Generic Configuration"
    },
    "desc_name": {
      "desc": "Bridge name, used as a human-readable description of the bridge.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to the HStreamDB. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "payload": {
      "desc": "The payload to be forwarded to the HStreamDB. Placeholders supported.",
      "label": "Payload"
    },
    "config": {
      "desc": "HStreamDB connection config",
      "label": "Connection config"
    },
    "name": {
      "desc": "Connector name, used as a human-readable description of the connector.",
      "label": "Connector Name"
    },
    "ordering_key": {
      "desc": "HStreamDB Ordering Key",
      "label": "HStreamDB Ordering Key"
    },
    "pool_size": {
      "desc": "HStreamDB Pool Size",
      "label": "HStreamDB Pool Size"
    },
    "stream_name": {
      "desc": "HStreamDB Stream Name",
      "label": "HStreamDB Stream Name"
    },
    "type": {
      "desc": "The Connector Type.",
      "label": "Connector Type"
    },
    "url": {
      "desc": "HStreamDB Server URL",
      "label": "HStreamDB Server URL"
    }
  },
  "emqx_ee_bridge_influxdb": {
    "config_enable": {
      "desc": "Enable or disable this bridge.",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for an InfluxDB bridge.",
      "label": "InfluxDB Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type.",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to the InfluxDB. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "write_syntax": {
      "desc": "Conf of InfluxDB line protocol to write data points. It is a text-based format that provides the measurement, tag set, field set, and timestamp of a data point, and placeholder supported.\nSee also [InfluxDB 2.3 Line Protocol](https://docs.influxdata.com/influxdb/v2.3/reference/syntax/line-protocol/) and\n[InfluxDB 1.8 Line Protocol](https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/) </br>\nTLDR:</br>\n```\n<measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]\n```\nPlease note that a placeholder for an integer value must be annotated with a suffix `i`. For example `${'{'}payload.int_value{'}'}i`.",
      "label": "Write Syntax"
    },
    "bucket": {
      "desc": "InfluxDB bucket name.",
      "label": "Bucket"
    },
    "database": {
      "desc": "InfluxDB database.",
      "label": "Database"
    },
    "influxdb_api_v1": {
      "desc": "InfluxDB's protocol. Support InfluxDB v1.8 and before.",
      "label": "HTTP API Protocol"
    },
    "influxdb_api_v2": {
      "desc": "InfluxDB's protocol. Support InfluxDB v2.0 and after.",
      "label": "HTTP API V2 Protocol"
    },
    "org": {
      "desc": "Organization name of InfluxDB.",
      "label": "Organization"
    },
    "password": {
      "desc": "InfluxDB password.",
      "label": "Password"
    },
    "precision": {
      "desc": "InfluxDB time precision.",
      "label": "Time Precision"
    },
    "protocol": {
      "desc": "InfluxDB's protocol. HTTP API or HTTP API V2.",
      "label": "Protocol"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.</br>\nA host entry has the following form: `Host[:Port]`.</br>\nThe InfluxDB default port 8086 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "token": {
      "desc": "InfluxDB token.",
      "label": "Token"
    },
    "username": {
      "desc": "InfluxDB username.",
      "label": "Username"
    }
  },
  "emqx_ee_bridge_kafka": {
    "connect_timeout": {
      "desc": "Maximum wait time for TCP connection establishment (including authentication time if enabled).",
      "label": "Connect Timeout"
    },
    "producer_opts": {
      "desc": "Local MQTT data source and Kafka bridge configs.",
      "label": "MQTT to Kafka"
    },
    "min_metadata_refresh_interval": {
      "desc": "Minimum time interval the client has to wait before refreshing Kafka broker and topic metadata. Setting too small value may add extra load on Kafka.",
      "label": "Min Metadata Refresh Interval"
    },
    "kafka_producer": {
      "desc": "Kafka Producer configuration.",
      "label": "Kafka Producer"
    },
    "producer_buffer": {
      "desc": "Configure producer message buffer.\n\nTell Kafka producer how to buffer messages when EMQX has more messages to send than Kafka can keep up, or when Kafka is down.",
      "label": "Message Buffer"
    },
    "socket_send_buffer": {
      "desc": "Fine tune the socket send buffer. The default value is tuned for high throughput.",
      "label": "Socket Send Buffer Size"
    },
    "desc_name": {
      "desc": "Bridge name, used as a human-readable description of the bridge.",
      "label": "Bridge Name"
    },
    "consumer_offset_commit_interval_seconds": {
      "desc": "Defines the time interval between two offset commit requests sent for each consumer group.",
      "label": "Offset Commit Interval"
    },
    "consumer_max_batch_bytes": {
      "desc": "Set how many bytes to pull from Kafka in each fetch request. Please note that if the configured value is smaller than the message size in Kafka, it may negatively impact the fetch performance.",
      "label": "Fetch Bytes"
    },
    "socket_receive_buffer": {
      "desc": "Fine tune the socket receive buffer. The default value is tuned for high throughput.",
      "label": "Socket Receive Buffer Size"
    },
    "consumer_topic_mapping": {
      "desc": "Defines the mapping between Kafka topics and MQTT topics. Must contain at least one item.",
      "label": "Topic Mapping"
    },
    "producer_kafka_opts": {
      "desc": "Kafka producer configs.",
      "label": "Kafka Producer"
    },
    "kafka_topic": {
      "desc": "Kafka topic name",
      "label": "Kafka Topic Name"
    },
    "consumer_kafka_topic": {
      "desc": "Kafka topic to consume from.",
      "label": "Kafka Topic"
    },
    "auth_username_password": {
      "desc": "Username/password based authentication.",
      "label": "Username/password Auth"
    },
    "auth_sasl_password": {
      "desc": "SASL authentication password.",
      "label": "Password"
    },
    "kafka_message_timestamp": {
      "desc": "Which timestamp to use. The timestamp is expected to be a millisecond precision Unix epoch which can be in string format, e.g. <code>1661326462115</code> or <code>'1661326462115'</code>. When the desired data field for this template is not found, or if the found data is not a valid integer, the current system timestamp will be used.",
      "label": "Message Timestamp"
    },
    "buffer_mode": {
      "desc": "Message buffer mode.\n\n<code>memory</code>: Buffer all messages in memory. The messages will be lost in case of EMQX node restart\n<code>disk</code>: Buffer all messages on disk. The messages on disk are able to survive EMQX node restart.\n<code>hybrid</code>: Buffer message in memory first, when up to certain limit (see <code>segment_bytes</code> config for more information), then start offloading messages to disk, Like <code>memory</code> mode, the messages will be lost in case of EMQX node restart.",
      "label": "Buffer Mode"
    },
    "consumer_mqtt_qos": {
      "desc": "MQTT QoS used to publish messages consumed from Kafka.",
      "label": "QoS"
    },
    "consumer_key_encoding_mode": {
      "desc": "Defines how the key from the Kafka message is encoded before being forwarded via MQTT.\n<code>none</code> Uses the key from the Kafka message unchanged.  Note: in this case, the key must be a valid UTF-8 string.\n<code>base64</code> Uses base-64 encoding on the received key.",
      "label": "Key Encoding Mode"
    },
    "auth_gssapi_kerberos": {
      "desc": "Use GSSAPI/Kerberos authentication.",
      "label": "GSSAPI/Kerberos"
    },
    "consumer_mqtt_opts": {
      "desc": "Local MQTT message publish.",
      "label": "MQTT publish"
    },
    "auth_kerberos_principal": {
      "desc": "SASL GSSAPI authentication Kerberos principal. For example <code>client_name{'@'}MY.KERBEROS.REALM.MYDOMAIN.COM</code>, NOTE: The realm in use has to be configured in /etc/krb5.conf in EMQX nodes.",
      "label": "Kerberos Principal"
    },
    "socket_opts": {
      "desc": "Extra socket options.",
      "label": "Socket Options"
    },
    "consumer_mqtt_topic": {
      "desc": "Local topic to which consumed Kafka messages should be published to.",
      "label": "MQTT Topic"
    },
    "consumer_offset_reset_policy": {
      "desc": "Defines from which offset a consumer should start fetching when there is no commit history or when the commit history becomes invalid.",
      "label": "Offset Reset Policy"
    },
    "partition_count_refresh_interval": {
      "desc": "The time interval for Kafka producer to discover increased number of partitions.\nAfter the number of partitions is increased in Kafka, EMQX will start taking the \ndiscovered partitions into account when dispatching messages per <code>partition_strategy</code>.",
      "label": "Partition Count Refresh Interval"
    },
    "max_batch_bytes": {
      "desc": "Maximum bytes to collect in a Kafka message batch. Most of the Kafka brokers default to a limit of 1 MB batch size. EMQX's default value is less than 1 MB in order to compensate Kafka message encoding overheads (especially when each individual message is very small). When a single message is over the limit, it is still sent (as a single element batch).",
      "label": "Max Batch Bytes"
    },
    "required_acks": {
      "desc": "Required acknowledgements for Kafka partition leader to wait for its followers before it sends back the acknowledgement to EMQX Kafka producer\n\n<code>all_isr</code>: Require all in-sync replicas to acknowledge.\n<code>leader_only</code>: Require only the partition-leader's acknowledgement.\n<code>none</code>: No need for Kafka to acknowledge at all.",
      "label": "Required Acks"
    },
    "metadata_request_timeout": {
      "desc": "Maximum wait time when fetching metadata from Kafka.",
      "label": "Metadata Request Timeout"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "socket_nodelay": {
      "desc": "When set to 'true', TCP buffer is sent as soon as possible. Otherwise, the OS kernel may buffer small TCP packets for a while (40 ms by default).",
      "label": "No Delay"
    },
    "authentication": {
      "desc": "Authentication configs.",
      "label": "Authentication"
    },
    "buffer_memory_overload_protection": {
      "desc": "Applicable when buffer mode is set to <code>memory</code>\nEMQX will drop old buffered messages under high memory pressure. The high memory threshold is defined in config <code>sysmon.os.sysmem_high_watermark</code>. NOTE: This config only works on Linux.",
      "label": "Memory Overload Protection"
    },
    "auth_sasl_mechanism": {
      "desc": "SASL authentication mechanism.",
      "label": "Mechanism"
    },
    "config_enable": {
      "desc": "Enable (true) or disable (false) this Kafka bridge.",
      "label": "Enable or Disable"
    },
    "consumer_mqtt_payload": {
      "desc": "The template for transforming the incoming Kafka message.  By default, it will use JSON format to serialize inputs from the Kafka message.  Such fields are:\n<code>headers</code>: an object containing string key-value pairs.\n<code>key</code>: Kafka message key (uses the chosen key encoding).\n<code>offset</code>: offset for the message.\n<code>topic</code>: Kafka topic.\n<code>ts</code>: message timestamp.\n<code>ts_type</code>: message timestamp type, which is one of <code>create</code>, <code>append</code> or <code>undefined</code>.\n<code>value</code>: Kafka message value (uses the chosen value encoding).",
      "label": "MQTT Payload Template"
    },
    "consumer_opts": {
      "desc": "Local MQTT publish and Kafka consumer configs.",
      "label": "MQTT to Kafka"
    },
    "kafka_consumer": {
      "desc": "Kafka Consumer configuration.",
      "label": "Kafka Consumer"
    },
    "desc_config": {
      "desc": "Configuration for a Kafka bridge.",
      "label": "Kafka Bridge Configuration"
    },
    "consumer_value_encoding_mode": {
      "desc": "Defines how the value from the Kafka message is encoded before being forwarded via MQTT.\n<code>none</code> Uses the value from the Kafka message unchanged.  Note: in this case, the value must be a valid UTF-8 string.\n<code>base64</code> Uses base-64 encoding on the received value.",
      "label": "Value Encoding Mode"
    },
    "buffer_per_partition_limit": {
      "desc": "Number of bytes allowed to buffer for each Kafka partition. When this limit is exceeded, old messages will be dropped in a trade for credits for new messages to be buffered.",
      "label": "Per-partition Buffer Limit"
    },
    "bootstrap_hosts": {
      "desc": "A comma separated list of Kafka <code>host[:port]</code> endpoints to bootstrap the client. Default port number is 9092.",
      "label": "Bootstrap Hosts"
    },
    "consumer_max_rejoin_attempts": {
      "desc": "Maximum number of times allowed for a member to re-join the group. If the consumer group can not reach balance after this configured number of attempts, the consumer group member will restart after a delay.",
      "label": "Max Rejoin Attempts"
    },
    "kafka_message_key": {
      "desc": "Template to render Kafka message key. If the template is rendered into a NULL value (i.e. there is no such data field in Rule Engine context) then Kafka's <code>NULL</code> (but not empty string) is used.",
      "label": "Message Key"
    },
    "kafka_message": {
      "desc": "Template to render a Kafka message.",
      "label": "Kafka Message Template"
    },
    "mqtt_topic": {
      "desc": "MQTT topic or topic as data source (bridge input).  Should not configure this if the bridge is used as a rule action.",
      "label": "Source MQTT Topic"
    },
    "kafka_message_value": {
      "desc": "Template to render Kafka message value. If the template is rendered into a NULL value (i.e. there is no such data field in Rule Engine context) then Kafka's <code>NULL</code> (but not empty string) is used.",
      "label": "Message Value"
    },
    "partition_strategy": {
      "desc": "Partition strategy is to tell the producer how to dispatch messages to Kafka partitions.\n\n<code>random</code>: Randomly pick a partition for each message\n<code>key_dispatch</code>: Hash Kafka message key to a partition number",
      "label": "Partition Strategy"
    },
    "buffer_segment_bytes": {
      "desc": "Applicable when buffer mode is set to <code>disk</code> or <code>hybrid</code>.\nThis value is to specify the size of each on-disk buffer file.",
      "label": "Segment File Bytes"
    },
    "consumer_kafka_opts": {
      "desc": "Kafka consumer configs.",
      "label": "Kafka Consumer"
    },
    "max_inflight": {
      "desc": "Maximum number of batches allowed for Kafka producer (per-partition) to send before receiving acknowledgement from Kafka. Greater value typically means better throughput. However, there can be a risk of message reordering when this value is greater than 1.",
      "label": "Max Inflight"
    },
    "auth_sasl_username": {
      "desc": "SASL authentication username.",
      "label": "Username"
    },
    "auth_kerberos_keytab_file": {
      "desc": "SASL GSSAPI authentication Kerberos keytab file path. NOTE: This file has to be placed in EMQX nodes, and the EMQX service runner user requires read permission.",
      "label": "Kerberos keytab file"
    },
    "compression": {
      "desc": "Compression method.",
      "label": "Compression"
    }
  },
  "emqx_ee_bridge_mongodb": {
    "collection": {
      "desc": "The collection where data will be stored into",
      "label": "Collection"
    },
    "desc_config": {
      "desc": "Configuration for MongoDB Bridge",
      "label": "MongoDB Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type.",
      "label": "Bridge Type"
    },
    "enable": {
      "desc": "Enable or disable this MongoDB Bridge",
      "label": "Enable or disable"
    },
    "mongodb_rs_conf": {
      "desc": "MongoDB (Replica Set) configuration",
      "label": "MongoDB (Replica Set) Configuration"
    },
    "mongodb_sharded_conf": {
      "desc": "MongoDB (Sharded) configuration",
      "label": "MongoDB (Sharded) Configuration"
    },
    "mongodb_single_conf": {
      "desc": "MongoDB (Standalone) configuration",
      "label": "MongoDB (Standalone) Configuration"
    },
    "payload_template": {
      "desc": "The template for formatting the outgoing messages.  If undefined, rule engine will use JSON format to serialize all visible inputs, such as clientid, topic, payload etc.",
      "label": "Payload template"
    },
    "auth_source": {
      "desc": "Database name associated with the user's credentials.",
      "label": "Auth Source"
    },
    "connect_timeout": {
      "desc": "The duration to attempt a connection before timing out.",
      "label": "Connect Timeout"
    },
    "desc_rs": {
      "desc": "Settings for replica set.",
      "label": "Setting Replica Set"
    },
    "desc_sharded": {
      "desc": "Settings for sharded cluster.",
      "label": "Setting Sharded Cluster"
    },
    "desc_single": {
      "desc": "Settings for a single MongoDB instance.",
      "label": "Setting Single MongoDB"
    },
    "desc_topology": {
      "desc": "Topology of MongoDB.",
      "label": "Setting Topology"
    },
    "heartbeat_period": {
      "desc": "Controls when the driver checks the state of the MongoDB deployment. Specify the interval between checks, counted from the end of the previous check until the beginning of the next one. If the number of connections is increased (which will happen, for example, if you increase the pool size), you may need to increase this period as well to avoid creating too many log entries in the MongoDB log file.",
      "label": "Heartbeat period"
    },
    "local_threshold": {
      "desc": "The size of the latency window for selecting among multiple suitable MongoDB instances.",
      "label": "Local Threshold"
    },
    "max_overflow": {
      "desc": "Max Overflow.",
      "label": "Max Overflow"
    },
    "min_heartbeat_period": {
      "desc": "Controls the minimum amount of time to wait between heartbeats.",
      "label": "Minimum Heartbeat Period"
    },
    "overflow_check_period": {
      "desc": "Period for checking if there are more workers than configured (\"overflow\").",
      "label": "Overflow Check Period"
    },
    "overflow_ttl": {
      "desc": "Period of time before workers that exceed the configured pool size (\"overflow\") to be terminated.",
      "label": "Overflow TTL"
    },
    "r_mode": {
      "desc": "Read mode.",
      "label": "Read Mode"
    },
    "replica_set_name": {
      "desc": "Name of the replica set.",
      "label": "Replica Set Name"
    },
    "rs_mongo_type": {
      "desc": "Replica set. Must be set to 'rs' when MongoDB server is running in 'replica set' mode.",
      "label": "Replica set"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe MongoDB default port 27017 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "server_selection_timeout": {
      "desc": "Specifies how long to block for server selection before throwing an exception.",
      "label": "Server Selection Timeout"
    },
    "servers": {
      "desc": "A Node list for Cluster to connect to. The nodes should be separated with commas, such as: `Node[,Node].`\nFor each Node should be: The IPv4 or IPv6 address or the hostname to connect to.\nA host entry has the following form: `Host[:Port]`.\nThe MongoDB default port 27017 is used if `[:Port]` is not specified.",
      "label": "Servers"
    },
    "sharded_mongo_type": {
      "desc": "Sharded cluster. Must be set to 'sharded' when MongoDB server is running in 'sharded' mode.",
      "label": "Sharded cluster"
    },
    "single_mongo_type": {
      "desc": "Standalone instance. Must be set to 'single' when MongoDB server is running in standalone mode.",
      "label": "Standalone instance"
    },
    "socket_timeout": {
      "desc": "The duration to attempt to send or to receive on a socket before the attempt times out.",
      "label": "Socket Timeout"
    },
    "srv_record": {
      "desc": "Use DNS SRV record.",
      "label": "Srv Record"
    },
    "w_mode": {
      "desc": "Write mode.",
      "label": "Write Mode"
    },
    "wait_queue_timeout": {
      "desc": "The maximum duration that a worker can wait for a connection to become available.",
      "label": "Wait Queue Timeout"
    }
  },
  "emqx_ee_bridge_mysql": {
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for an HStreamDB bridge.",
      "label": "HStreamDB Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name, used as a human-readable description of the bridge.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to MySQL. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe MySQL default port 3306 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "sql": {
      "desc": "SQL Template",
      "label": "SQL Template"
    }
  },
  "emqx_ee_bridge_pgsql": {
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for an PostgreSQL bridge.",
      "label": "PostgreSQL Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to PostgreSQL. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe PostgreSQL default port 5432 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "sql": {
      "desc": "SQL Template",
      "label": "SQL Template"
    }
  },
  "emqx_ee_bridge_redis": {
    "command_template": {
      "desc": "Redis command template used to export messages. Each list element stands for a command name or its argument.\nFor example, to push payloads in a Redis list by key `msgs`, the elements should be the following:\n`rpush`, `msgs`, `${'{'}payload{'}'}`.",
      "label": "Redis Command Template"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a Redis bridge.",
      "label": "Redis Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name, used as a human-readable description of the bridge.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Redis. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "cluster": {
      "desc": "Cluster mode. Must be set to 'cluster' when Redis server is running in clustered mode.",
      "label": "Cluster Mode"
    },
    "database": {
      "desc": "Redis database ID.",
      "label": "Database ID"
    },
    "sentinel": {
      "desc": "Sentinel mode. Must be set to 'sentinel' when Redis server is running in sentinel mode.",
      "label": "Sentinel Mode"
    },
    "sentinel_desc": {
      "desc": "The cluster name in Redis sentinel mode.",
      "label": "Cluster Name"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe Redis default port 6379 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "servers": {
      "desc": "A Node list for Cluster to connect to. The nodes should be separated with commas, such as: `Node[,Node].`\nFor each Node should be: The IPv4 or IPv6 address or the hostname to connect to.\nA host entry has the following form: `Host[:Port]`.\nThe Redis default port 6379 is used if `[:Port]` is not specified.",
      "label": "Servers"
    },
    "single": {
      "desc": "Single mode. Must be set to 'single' when Redis server is running in single mode.",
      "label": "Single Mode"
    }
  },
  "emqx_ee_bridge_rocketmq": {
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a RocketMQ bridge.",
      "label": "RocketMQ Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to RocketMQ. All MQTT `PUBLISH` messages with the topic\nmatching the `local_topic` will be forwarded.</br>\nNOTE: if the bridge is used as a rule action, `local_topic` should be left empty otherwise the messages will be duplicated.",
      "label": "Local Topic"
    },
    "template": {
      "desc": "Template, the default value is empty. When this value is empty the whole message will be stored in the RocketMQ",
      "label": "Template"
    },
    "refresh_interval": {
      "desc": "RocketMQ Topic Route Refresh Interval.",
      "label": "Topic Route Refresh Interval"
    },
    "security_token": {
      "desc": "RocketMQ Server Security Token",
      "label": "Security Token"
    },
    "send_buffer": {
      "desc": "The socket send buffer size of the RocketMQ driver client.",
      "label": "Send Buffer Size"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe RocketMQ default port 9876 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "topic": {
      "desc": "RocketMQ Topic",
      "label": "RocketMQ Topic"
    }
  },
  "emqx_ee_bridge_tdengine": {
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for an TDengine bridge.",
      "label": "TDengine Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to TDengine. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.</br>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe TDengine default port 6041 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "sql": {
      "desc": "SQL Template",
      "label": "SQL Template"
    }
  },
  "emqx_ee_bridge_sqlserver": {
    "server": {
      "label": "Server Host",
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/><br/>A host entry has the following form: `Host[:Port]`.<br/><br/>The SQL Server default port 1433 is used if `[:Port]` is not specified."
    },
    "driver": {
      "label": "SQL Server Driver Name",
      "desc": "SQL Server Driver Name"
    },
    "sql": {
      "label": "SQL Template",
      "desc": "SQL Template"
    },
    "local_topic": {
      "label": "Local Topic",
      "desc": "The MQTT topic filter to be forwarded to Microsoft SQL Server. All MQTT 'PUBLISH' messages with the topic<br/>matching the local_topic will be forwarded.</br><br/>NOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is<br/>configured, then both the data got from the rule and the MQTT messages that match local_topic<br/>will be forwarded."
    }
  }
}